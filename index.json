[{"authors":["Dhruv Singal","Palak Agarwal","Saket Jhunjhunwala","Subhajit Roy"],"categories":["parsing"],"content":"","date":1540070570,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540070570,"objectID":"c7a38050818256a3811b8d8178c00584","permalink":"https://singaldhruv.github.io/publication/lpar2018/","publishdate":"2018-10-20T17:22:50-04:00","relpermalink":"/publication/lpar2018/","section":"publication","summary":"In this work, we propose the notion of a Parse Conditionâ€”a logical condition that is satisfiable if and only if a given string w can be successfully parsed using a grammar G. Further, we propose an algorithm for building an SMT encoding of such parse conditions for LL(1) grammars and demonstrate its utility by building two applications over it: automated repair of syntax errors in Tiger programs and automated parser synthesis to automatically synthesize LL(1) parsers from examples. We implement our ideas into a tool, Cyclops, that is able to successfully repair 80% of our benchmarks (675 buggy Tiger programs), clocking an average of 30 seconds per repair and synthesize parsers for interesting languages from examples. Like verification conditions (encoding a program in logic) have found widespread applications in program analysis, we believe that Parse Conditions can serve as a foundation for interesting applications in syntax analysis.","tags":["SMT","parsing","LL1","constraint solving"],"title":"Parse Condition: Symbolic Encoding of LL(1) Parsing","type":"publication"},{"authors":["Ritwik Sinha","Dhruv Singal","Pranav Maneriker","Kushal Chawla","Yash Shrivastava","Deepak Pai","Atanu Ranjan Sinha"],"categories":["data mining"],"content":"","date":1534800170,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534800170,"objectID":"58eae03210a7f88e30883c66af848a3e","permalink":"https://singaldhruv.github.io/publication/adkdd2018/","publishdate":"2018-08-20T17:22:50-04:00","relpermalink":"/publication/adkdd2018/","section":"publication","summary":"Orchestration of campaigns for online display advertising requires marketers to forecast audience size at the granularity of specific attributes of web traffic, characterized by the categorical nature of all attributes (e.g. {US, Chrome, Mobile}). With each attribute taking many values, the very large attribute combination set makes estimating audience size for any specific attribute combination challenging. We modify Eclat, a frequent itemset mining (FIM) al- gorithm, to accommodate categorical variables. For consequent frequent and infrequent itemsets, we then provide forecasts using time series analysis with conditional probabilities to aid approxi- mation. An extensive simulation, based on typical characteristics of audience data, is built to stress test our modified-FIM approach. In two real datasets, comparison with baselines including neural network models, shows that our method lowers computation time of FIM for categorical data. On hold out samples we show that the proposed forecasting method outperforms these baselines.","tags":["data mining","deep learning","online advertising","display advertising","time series"],"title":"Forecasting Granular Audience Size for Online Advertising","type":"publication"},{"authors":["Sumit Shekhar","Dhruv Singal","Harvineet Singh","Manav Kedia","Akhil Shetty"],"categories":["computer vision"],"content":"","date":1508534570,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508534570,"objectID":"3a809e1f02c310abced3d69ac6233b16","permalink":"https://singaldhruv.github.io/publication/iccvw2017/","publishdate":"2017-10-20T17:22:50-04:00","relpermalink":"/publication/iccvw2017/","section":"publication","summary":"With the explosion of video content on the Internet, there is a need for research on methods for video analysis which take human cognition into account. One such cognitive measure is memorability, or the ability to recall visual content after watching it. Prior research has looked into image memorability and shown that it is intrinsic to visual content, but the problem of modeling video memorability has not been addressed sufficiently. In this work, we develop a prediction model for video memorability, including complexities of video content in it. Detailed feature analysis reveals that the proposed method correlates well with existing findings on memorability. We also describe a novel experiment of predicting video sub-shot memorability and show that our approach improves over current memorability methods in this task. Experiments on standard datasets demonstrate that the proposed metric can achieve results on par or better than the state-of-the art methods for video summarization.","tags":["video memorability","memorability","video","deep learning"],"title":"Show and Recall: Learning What Makes Videos Memorable","type":"publication"}]